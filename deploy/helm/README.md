# Helm chart for Camo Fleet on k3s

This chart bundles the control plane, UI, workers, and VNC gateway so that the complete Camo Fleet stack can be deployed on any Kubernetes cluster. The defaults in `values.yaml` are tailored for a single-node k3s environment and match the public address `https://camofleet.services.synestra.tech/` required for the Traefik exposure described later in this guide.

> **Important:** The chart intentionally does **not** create an Ingress or Traefik IngressRoute. Apply the Traefik manifests from `deploy/traefik` after Helm finishes to publish the stack on the internet.

## Prerequisites

1. A working k3s cluster with kubectl access.
2. [Helm 3](https://helm.sh/docs/intro/install/) installed on the workstation that talks to the cluster.
3. Container images for every Camo Fleet component pushed to a registry reachable from the cluster. Соберите и загрузите (или
   сделайте доступными через приватный реестр) **все** следующие образы:
   - `camofleet-control` (Dockerfile: `docker/Dockerfile.control`)
   - `camofleet-ui` (Dockerfile: `docker/Dockerfile.ui`)
   - `camofleet-worker` (Dockerfile: `docker/Dockerfile.worker`)
   - `camofleet-runner` (Dockerfile: `docker/Dockerfile.runner`)
   - `camofleet-worker-vnc` (Dockerfile: `docker/Dockerfile.worker` с переменной окружения `WORKER_SUPPORTS_VNC=true` применяется Helm-чартом автоматически)
   - `camofleet-runner-vnc` (Dockerfile: `docker/Dockerfile.runner-vnc`)
   - `camofleet-worker-vnc-gateway` (Dockerfile: `docker/Dockerfile.vnc-gateway`)


   Если вы используете другие теги, обязательно пропишите их в `values.yaml` перед установкой.
4. DNS records and TLS certificate for `camofleet.services.synestra.tech` (either a wildcard certificate or a certificate generated by Traefik/Let's Encrypt).

## 1. Prepare a values file

Copy the default values and adjust them for your environment. Beginners usually make fewer mistakes if they keep the original file untouched:

```bash
cp deploy/helm/camofleet/values.yaml my-values.yaml
```

Open `my-values.yaml` and adjust the options that differ in your environment:

- **`global.imageRegistry`** – замените пустое значение на адрес реестра, где лежат собранные образы (например, `registry.synestra.tech`). Если в теге уже указан полный путь, оставьте поле пустым.
- **Component tags** – пропишите нужные теги (`control.image.tag`, `worker.image.tag` и т.д.), если вы используете не `latest`.
- **`ui.controlHost`** – установите домен, по которому Traefik проксирует API. Для публичного сценария оставьте `camofleet.services.synestra.tech`.
- **`workerVnc.controlOverrides`** – задайте внешние ссылки, совпадающие с Traefik-роутингом:
  ```yaml
  workerVnc:
    controlOverrides:
      ws: wss://camofleet.services.synestra.tech/vnc/websockify?token={id}
      http: https://camofleet.services.synestra.tech/vnc/{id}
  ```
  Эти значения попадут в `CONTROL_WORKERS`, поэтому UI и control-plane будут возвращать корректные публичные URL для noVNC.
- **`control.config.workers`** – оставьте `null`, чтобы Helm автоматически добавил сервисы `camofleet-worker` и `camofleet-worker-vnc`. Меняйте список только если подключаете внешние воркеры или меняете имена сервисов.

Save the file when you are done.

## 2. Install or upgrade the release

Run the following command from the repository root:

```bash
helm upgrade --install camofleet deploy/helm/camofleet \
  --namespace camofleet \
  --create-namespace \
  -f my-values.yaml
```

Helm prints a summary similar to:

```
Release "camofleet" has been upgraded. Happy Helming!
```

### Автоматизируем установку/обновление с нуля

Если вы хотите воспроизводимый процесс, который полностью собирает свежие образы, очищает containerd и применяет Helm-релиз, воспользуйтесь следующим скриптом. Он покрывает сценарий «с нуля»: клонирует репозиторий, пересобирает все образы, импортирует их в k3s и выполняет `helm upgrade --install`.

1. Скопируйте скрипт и сохраните его, например, в `deploy/helm/install.sh`.

   ```bash
   #!/usr/bin/env bash
   set -euo pipefail

   # --- настройте под себя ---
   GIT_URL="https://github.com/NeoGrAIph/camo-fleet.git" # адрес репозитория
   WORKDIR="$HOME/helm/repo/camo-fleet"                  # куда клонировать
   NAMESPACE="camofleet"                                 # namespace в k3s
   CONTAINERD_REF_PREFIX="docker.io/library"             # префикс ref при импорте в containerd
   IMAGE_REGISTRY="${CONTAINERD_REF_PREFIX}"             # значение для global.imageRegistry
   PUBLIC_HOST="camofleet.services.synestra.tech"        # публичный домен Traefik
   IMAGES=(
     "camofleet-control:docker/Dockerfile.control"
     "camofleet-ui:docker/Dockerfile.ui"
     "camofleet-worker:docker/Dockerfile.worker"
     "camofleet-runner:docker/Dockerfile.runner"
     "camofleet-worker-vnc:docker/Dockerfile.worker"
     "camofleet-runner-vnc:docker/Dockerfile.runner-vnc"
     "camofleet-worker-vnc-gateway:docker/Dockerfile.vnc-gateway"
   )

   # --- функции ---
   log() {
     echo -e "\033[1;32m[INFO]\033[0m $*"
   }

   err() {
     echo -e "\033[1;31m[ERROR]\033[0m $*" >&2
   }

   # --- подготовка репозитория ---
   mkdir -p "$(dirname "$WORKDIR")"
   if [ ! -d "$WORKDIR/.git" ]; then
     log "Клонирование репозитория..."
     git clone "$GIT_URL" "$WORKDIR"
   else
     log "Обновление репозитория..."
     cd "$WORKDIR"
     git fetch --all
     git reset --hard origin/main
   fi
   cd "$WORKDIR"

   # --- сборка образов ---
   for mapping in "${IMAGES[@]}"; do
     IMAGE="${mapping%%:*}"
     DOCKERFILE="${mapping#*:}"
     IMAGE_TAG="${IMAGE}:latest"
     CONTAINERD_REF="${CONTAINERD_REF_PREFIX}/${IMAGE_TAG}"

     log "Удаление старого образа $IMAGE_TAG (если есть)..."
     sudo ctr -n k8s.io images rm "${CONTAINERD_REF}" || true
     docker rmi "${IMAGE_TAG}" || true

     log "Сборка образа $IMAGE_TAG..."
     docker build -t "${IMAGE_TAG}" -f "${DOCKERFILE}" .

     log "Импорт образа $IMAGE_TAG в containerd..."
     docker save "${IMAGE_TAG}" -o "${IMAGE}.tar"
     sudo ctr -n k8s.io images import "${IMAGE}.tar"
     rm -f "${IMAGE}.tar"
   done

   # --- значения Helm ---
   HELM_ARGS=(
     --namespace "${NAMESPACE}"
     --create-namespace
     --set-string "global.imageRegistry=${IMAGE_REGISTRY}"
     --set-string "ui.controlHost=${PUBLIC_HOST}"
     --set-string "workerVnc.controlOverrides.ws=wss://${PUBLIC_HOST}/vnc/websockify?token={id}"
     --set-string "workerVnc.controlOverrides.http=https://${PUBLIC_HOST}/vnc/{id}"
   )

   # --- деплой через helm ---
   log "Установка/обновление helm release camofleet..."
   helm upgrade --install camofleet deploy/helm/camofleet "${HELM_ARGS[@]}"

   log "Готово ✅"
   ```

2. Отредактируйте блок «настройте под себя»: укажите реестр, пространство имён и пути к Dockerfile. Если вы используете собственный приватный реестр k3s (`k3s ctr images import`), поменяйте `CONTAINERD_REF_PREFIX` и при необходимости задайте отличный от него `IMAGE_REGISTRY` (значение попадёт в `global.imageRegistry`). При необходимости замените `PUBLIC_HOST` на свой домен.
3. Дайте скрипту права на выполнение и запустите:

   ```bash
   chmod +x deploy/helm/install.sh
   ./deploy/helm/install.sh
   ```

Скрипт можно повторно запускать при выпуске новой версии: он удалит старые контейнерные образы, пересоберёт их и применит обновление Helm. После успешного завершения остаётся только повторно применить (или обновить) Traefik IngressRoute из `deploy/traefik`.

## 3. Confirm that the Pods are running

Wait until all Deployments become available:

```bash
kubectl get pods -n camofleet
```

You should see `camofleet-control`, `camofleet-ui`, `camofleet-worker`, and `camofleet-worker-vnc` in the `Running` state. Убедитесь, что у `camofleet-worker-vnc` оба контейнера (`runner` и `gateway`) находятся в статусе `READY` — именно gateway проксирует noVNC трафик через Traefik.

## 4. Publish the services with Traefik

The Helm chart intentionally stops at creating Services. Apply the manifests in `deploy/traefik` to expose the UI, API, and VNC gateway through Traefik with a single public HTTPS address. The Traefik manifests include detailed, beginner-friendly instructions.

## 5. Проверяем сквозной путь noVNC

После публикации убедитесь, что трафик noVNC действительно проходит по всей цепочке — от браузера пользователя до runner-а в воркере и обратно. Это можно сделать пошагово:

1. **Проверьте регистрацию воркеров.**
   ```bash
   kubectl get pods -n camofleet
   kubectl logs -n camofleet deployment/camofleet-control | grep "registered worker"
   ```
   В логах control-plane должны появиться записи о воркере `worker-vnc` с публичными URL вида `https://camofleet.services.synestra.tech/vnc`.

2. **Подготовьте несколько браузеров.** Откройте две независимые сессии (например, обычное окно + инкогнито) по адресу `https://camofleet.services.synestra.tech/`. Это позволит проверить, что одновременно работающие noVNC-клиенты не мешают друг другу.

3. **Создайте ручные VNC-сессии.** В каждом окне:
   - Зайдите в раздел запуска сессии (Manual Run).
   - Включите опцию VNC/live screen.
   - Запустите сессию и дождитесь статуса `RUNNING`.

4. **Откройте live-экран.** В таблице сессий нажмите `Open VNC` или `Live Screen`. Браузер загрузит noVNC iframe, который установит WebSocket-подключение на `wss://camofleet.services.synestra.tech/vnc?...`.

5. **Наблюдайте цепочку запросов.**
   - В DevTools → Network убедитесь, что открылись два WebSocket-подключения (по одному от каждого окна).
    - На кластере в отдельных терминалах выполните:
      ```bash
      kubectl logs -n camofleet deployment/camofleet-worker-vnc -c gateway -f
      kubectl logs -n camofleet deployment/camofleet-worker-vnc -c runner -f
      ```
      В логах контейнера gateway будут отображаться входящие подключения от Traefik, а в логах runner — выделение портов (`Allocated VNC port 69xx`) и обратный трафик к браузеру.

6. **Проверьте двусторонний обмен.** Попробуйте управлять браузером внутри noVNC (печать текста, навигация). Действия должны отражаться в UI обеих сессий, а логи control-plane подтвердят получение обновлений статуса.

Эта проверка подтверждает, что поток данных проходит по цепочке `Браузер → Traefik → camofleet-worker-vnc (gateway) → runner → worker → control-plane → UI → Браузер` и что несколько одновременных подключений обслуживаются корректно.

## Uninstalling

To remove all resources created by the chart:

```bash
helm uninstall camofleet -n camofleet
```

If you no longer need the namespace, delete it as well:

```bash
kubectl delete namespace camofleet
```
